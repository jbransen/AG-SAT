\documentclass{llncs}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[T1]{fontenc}
\usepackage{tikz}
\usetikzlibrary{arrows, automata}
\input{./formats.tex}

% Paper info
\title{Linear Ordered Attribute Grammar scheduling using SAT-solving}
\author{Jeroen Bransen\inst{1}  \and L. Thomas van Binsbergen\inst{2,1} \and Koen Claessen\inst{3} \and Atze Dijkstra\inst{1}}
\institute{Utrecht University, Utrecht, The Netherlands, \email{\{J.Bransen,atze\}@uu.nl}
\and Royal Holloway, University of London, Egham, UK, \email{Thomas.VanBinsbergen.2014@live.rhul.ac.uk}
\and Chalmers University of Technology, Gothenburg, Sweden, \email{koen@chalmers.se}}

% Wat handige shortcuts
\newif\iffinal\finalfalse
\newcommand{\REM}[3]{\iffinal\else\textcolor{#2}{[#1: #3]}\fi}
\newcommand{\Atze}[1]{\REM{Atze}{red}{#1}}
\newcommand{\Koen}[1]{\REM{Koen}{red}{#1}}
\newcommand{\Jeroen}[1]{\REM{Jeroen}{red}{#1}}
\newcommand{\Thomas}[1]{\REM{Thomas}{red}{#1}}

\newcommand{\figref}[1]{Figure~\ref{#1}}
\newcommand{\sectref}[1]{Section~\ref{#1}}

\begin{document}

\maketitle

\begin{abstract}
Many computations over trees can be expressed using attribute
grammars. Compilers for attribute grammars need to find an evaluation
order (or schedule) in order to generate efficient code. For the class
of linear ordered attribute grammars such a schedule can be found
statically, but this problem is known to be NP-hard.

In this paper, we show how to encode linear ordered attribute grammar
scheduling as a SAT-problem. Cycle-freeness of the dependency graphs
is expressed by making the graphs chordal, which is a new approach for
encoding such graph properties in SAT.

There are two main advantages to using a SAT-solver for scheduling:
(1) the scheduling algorithm runs much faster than existing scheduling
algorithms on real-world examples\Thomas{Waarmee vergelijken we? 
Kastens algoritme is niet voor LOAGs, het voordeel dat onze aanpak geen 
augmenting dependencies nodig heeft zou dan in de vergelijking genoemd moeten 
worden}, and (2) by adding extra constraints
we obtain fine-grained control over the resulting schedule, thereby
enabling new scheduling optimisations.


\keywords{Attribute Grammars, static analysis, SAT-solving}
\end{abstract}

\section{Introduction}
Attribute Grammars \cite{knuth68} are a formalism for describing the semantics of context-free languages, thereby making them suitable for the construction of compilers. Examples of compilers written using attribute grammars are JastAddJ \cite{Ekman:2007}, a Java compiler, and UHC \cite{Dijkstra:2009}, a Haskell compiler. The UHC is also the motivation for this paper and is used as a real world test case for testing the effectiveness of the given approach.

An attribute grammar essentially describes computations over trees, also known as folds or catamorphisms. Although the attribute grammar defines exactly \emph{what} should be computed, it does not define \emph{when} values should be computed. It is therefore up to the attribute grammar compiler (the compiler that translates the attribute grammar definition into a runtime evaluator) to find an evaluation order. Such evaluation order or schedule should satisfy the dependencies from the attribute grammar definition and must be found found statically, which means that for the given grammar an evaluation order should be found such that for every finite parse tree of the grammar the evaluation order should compute all values in a finite number of steps. Specifically, no cyclic data dependencies may occur at runtime for any given parse tree.

The class of \emph{ordered attribute grammars} \cite{kastens80} is a well-known subclass of attribute grammars for which a polynomial time scheduling algorithm exists. However, despite what the name suggests there exist attribute grammars for which a static evaluation order can be found that do not belong to the class of ordered attribute grammars. In our work on compiler construction we often encountered this situation, giving rise to the need of other scheduling algorithms \cite{bransen2012}. We therefore look at the class of \emph{linear ordered attribute grammars} in this paper, which is the largest class of attribute grammars for which a static evaluation order can be found. The problem of statically finding such evaluation order is known to be NP-complete \cite{engelfriet82}.

We solve the linear ordered attribute grammar scheduling problem by translating it to the Boolean satisfiability problem (SAT), one of the best-known NP-complete problems \cite{Cook:1971}. The SAT problem has been the subject of a lot of research and even though the worst case runtime of all known SAT-solving algorithms is exponential in the input size, many SAT-solvers work very well in practice. \Jeroen{todo: referenties hier, misschien naar SAT-solving overzicht?} By translating to SAT we can therefore use an efficient existing SAT-solver to solve our problem, and even benefit from future improvements in the SAT-community.

The core of the scheduling problem is essentially a set of dependency graphs (directed acyclic graphs) for which a total order on the nodes should be found such that all direct dependencies, which are coming from the input grammar, are satisfied. However, there is a certain interplay between the different dependency graphs resulting in indirect dependencies, coming from the order that is found in one dependency graph, that need to be satisfied another dependency graph. This interplay of dependencies, which is explained later in detail, is what makes the problem so hard.

To encode this problem in SAT we represent each edge as a Boolean variable, with its value indicating the direction of the edge. For the direct dependencies the value is already set, but for the rest of the variables the SAT-solver may choose the direction of the edge. To ensure cycle-freeness this requires us to encode transitivity with SAT-constraints, which in the straight-forward solution leads to a number of extra constraints cubing in the number of variables. To avoid that problem we make our graphs \emph{chordal} \cite{Dirac:1961}, which means that for every cycle of size $> 3$, there must exist an edge between two non-adjacent nodes in the cycle. In other words, if there exists a cycle in the graph, there must also exist a cycle of at most three nodes. This allows us to encode cycle-freeness much more efficiently by only disallowing cycles of length three.

Apart from the fact that this translation to SAT helps in efficiently (in practice) solving the scheduling problem, there also is another benefit: it is now possible to encode extra constraints on the resulting schedule. We show two \Jeroen{de 2e moet nog uitgewerkt worden} scheduling optimisations that are interesting from an attribute grammar perspective, for which the optimal schedule can be found efficiently by expressing the optimisation in the SAT problem.

This paper therefore makes the following main contributions:
\begin{itemize}
\item We show how to encode the problem of scheduling linear ordered attribute grammars as a SAT-problem
\item We show that chordal graphs can be used to encode cycle-freeness in SAT-problems involving graph encoding
\item We show how certain attribute grammar optimisations can be encode in the SAT-problem
\end{itemize}
Furthermore, we have implement the described techniques in the UUAGC\footnote{\url{http://www.cs.uu.nl/wiki/HUT/AttributeGrammarSystem}} \cite{combinator-languages} and show that the technique works well in practice for the UHC.

The outline of the paper is as follows. We start in \sectref{sect:loag} by explaining linear ordered attribute grammars and the difficulties in scheduling in more detail. We then describe the translation to SAT in \sectref{sect:translation} and show the effectiveness of our approach in \sectref{sect:results}. In \sectref{sect:optimisations} we describe the two attribute grammar optimisations and finally in \sectref{sect:conclusion} we discuss some problems and conclude.

\Jeroen{todo in intro: cite Minisat?, cite Binsbergen:2015 (PEPM)}


\section{Linear Ordered Attribute Grammars} \label{sect:loag}
\Jeroen{todo: Betere introduction LOAGs, plaatjes om scheduling toe te lichten, dependency graphs utleggen}

\section{Translation to SAT} \label{sect:translation}
\Jeroen{todo: vertaling, chordal graphs uitleggen}

\section{Empirical results} \label{sect:results}
\Jeroen{todo: getallen over UHC laten zien, het werkt echt}

\section{Optimisations} \label{sect:optimisations}
\Jeroen{todo: laten zien dat we totaal aantal visits kunnen minimaliseren en dat we sommige attributen vroeg kunnen schedulen, en intuitie geven waarom dit nuttig is (meer hebben we ook nog niet)}

\section{Conclusion and discussion} \label{sect:conclusion}
\Jeroen{todo: het werkt, misschien is andere representatie beter, en het is onvoorspelbaarder dus misschien duren sommige ags ineens heel lang om te schedulen}


% -----------------------------------

\section{Attribute Grammar}
An attribute grammars consists of three parts: a context-free grammar 
describing abstract syntax, a set of inherited and synthesized attributes
assigned to every non-terminal of the grammar and a set of semantic function
definitions. A production rule of a context-free grammar has one non-terminal
as its left-hand side and any number of terminals and non-terminals as its
right-hand side. The non-terminals occurring in production rules are considered
to be non-terminal \emph{occurrences}. A non-terminal occurrence of 
non-terminal $X$ automatically obtains the attributes of $X$ as attribute 
occurrences. The semantic function definitions describe how some attribute 
occurrences of a production rule are calculated in terms of other attribute
occurrences and terminal symbols of that rule. For our purposes we can safely
ignore any terminal symbols. Figure \ref{fig:productions} shows
examples of production rules displayed as diagrams.

\mypic{productions}{Diagrams showing productions, $P1: (lhs:X) \rightarrow 
\alpha$, $P2: (lhs:Y) \rightarrow \alpha (x:X) \beta$, $P3: (lhs:Z)
\rightarrow \alpha (y:Y) \beta (x:X) \gamma$, where $\alpha$, $\beta$,
$\gamma$ are arbitrary terminal symbols.}

All non-terminal occurrences are named, e.g. $(x:X)$ is an occurrence of 
non-terminal $X$ named $x$. Synthesized attributes are shown to the right
and inherited attributes are shown to the left of their respective
non-terminal occurrences. The gray attribute occurrences (inherited in the
left-hand side and synthesized in the right-hand side) are input occurrences,
the others are output occurrences. 

The input occurrences of one production are the output occurrences of another.
Production rules can be `pasted' together to form a tree\cite{knuth68}. 
This task is performed by a parser forming a derivation 
tree\Thomas{Ik stop hier maar even met typen om 
niet te veel uit te wijden, maar eigenlijk zou ik hier nog willen vertellen
dat: 1) Input occurrences van buitenaf worden aangeleverd, 2) dat om dit
te kunnen doen er wel definities voor output occurrences nodig zijn, 
3) dat de pijlen in het figuur (omgekeerde) dependencies weergeven.}.


\section{Linear Ordered Attribute Grammars}
A linear ordered attribute grammar is an attribute grammar for which we can 
find a evaluation order statically\Thomas{Hier zouden we misschien een 
voorbeeld van een parse tree willen laten zien met een interessante 
evaluation order, helaas zijn dat soort plaatjes veel te groot}. 
That is, based on only the information of
non-terminals and productions from the grammar, we can ensure that an 
evaluation order exists for any valid sentence of the grammar.
We show a static evaluation order exists by constructing evaluation orders 
for all production rules such that they satisfy certain properties.
Most importantly: when pasting together production rules to form a 
derivation tree, the evaluation orders for those trees can not contradict 
each other. Figure \ref{fig:contradiction} shows what can go wrong.

\mypic{contradiction}{The evaluation orders depicted by the arrows
of productions $P4$, $P5$ and $P6$ contradict each other: they can
not be combined without forming a cycle.}

Any non-terminal occurrence of $X$ can be replaced by any
of the productions of $X$. Therefore, when constructing an evaluation
order for a production in which $X$ occurs in the right-hand side,
all the evaluation orders constructed for productions in which 
$X$ occurs in the left-hand side need to be taken account.
Changing the evaluation order of one production rule is likely to demand 
a change in the evaluation order of some other production. This is 
what makes LOAG scheduling NP-hard.

In a production graph we can represent the evaluation order of other graphs
using induced dependencies (graph $ID_P$ from Kastens) by adding an 
arrow $a\rightarrow b$ to a non-terminal $X$ if $X$ occurs in some other
production in which there is a path between its $a$ and $b$.
Figure \ref{fig:idp} shows the induced dependency graph of production
$P4$.

\mypic{idp}{The gray edges are induced dependency, showing that they
evaluation orders of Figure \ref{fig:contradiction} are not compatible.}

The induced dependencies will be the same for every occurrence of every
non-terminal and are gathered in induced dependency graphs for 
non-terminals (Kastens $ID_S$).

We can now look at the problem from two directions: 1) we change the
evaluation order of a production and update graph $ID_S$ which might
then affect other production rules and update until all evaluation
orders are compatible\Thomas{AOAG} or 2) we make the decision at non-terminal 
level and decide an order for evaluating the attributes of a non-terminal 
such that an order at production level is still 
possible\Thomas{LOAG, De intuitie achter dit idee zijn de visit-sequences
en intra-visit dependencies, maar die willen we niet noemen}.

\section{Chordal Graphs}
The chords of a chordal graph can be seen as representing the assignment
to the variables `behind' that chord. If there is a chord $a\leftrightarrow b$
then an assignment $a\leftrightarrow^\rightarrow b$ implies that there is 
no path $b\longrightarrow a$ assuming cycle-freeness. This intuition allows
us to see why all assignments that lead to no cycles of length 3 lead to 
no cycles at all in a chordal graph: every cycle of length $> 3$ is 
split by a chord, so one side of the cycles assignments is represented by
the chord in the other.

\mypic{simplechord}{There can not exists a cycle w-n-e-s without either
a cycle n-s-w or n-e-s.}

\Thomas{In mijn scriptie gebruik ik problem graphs en assignment graphs
om de stap van undirected naar directed graphs te maken. Later kwam ik
echter het begrip `orientation' tegen, met hetzelfde doel.}

\section{Definitions}
\input{./loags.tex}

\bibliographystyle{splncs}
\bibliography{biblio}


\end{document}
